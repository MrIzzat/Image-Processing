{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# What is this notebook?\n",
        "\n",
        "I created this notebook to learn and apply image processing techniques."
      ],
      "metadata": {
        "id": "L6heE4rx2Phf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "JtHQUQW4zLCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look into:\n",
        "\n",
        "* Blurring before binarization\n",
        "* Everything here: https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html\n",
        "* https://medium.com/@jaskaranbhatia/unveiling-the-power-of-thresholding-a-must-learn-technique-for-image-segmentation-9a9fec180229\n",
        "* https://stackoverflow.com/questions/71425968/remove-horizontal-lines-with-open-cv"
      ],
      "metadata": {
        "id": "NHBKkNbTvE5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Image Processing"
      ],
      "metadata": {
        "id": "8CNHQg3NePrA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Histograms"
      ],
      "metadata": {
        "id": "-mMKIv_qfTXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An image's histogram is basically a histogram that plots the the number of occurneces of each intensity value in the image. It gives an idea about the intensity distribution of an image. It's another way of looking at an image. A histogram can give an intuition about the contrast, brightness intensity distribution etc."
      ],
      "metadata": {
        "id": "wD1t_V85mY9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From video: https://www.youtube.com/watch?v=F9TZb0XBow0&ab_channel=ProgrammingKnowledge"
      ],
      "metadata": {
        "id": "HwEl-Y8amWC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "x_YzfX-KAZpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "cHn6Gy29AcPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make graphs display in high quality"
      ],
      "metadata": {
        "id": "QRvycPaUD-ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "#%config InlineBackend.figure_format='png' To display back to low quality"
      ],
      "metadata": {
        "id": "ZF-tB25MD_G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Histogram of zeroes"
      ],
      "metadata": {
        "id": "qwoR-oYAmwv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the image"
      ],
      "metadata": {
        "id": "U4poxPaxAtCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "black_image = np.zeros((200,200),np.uint8)\n",
        "cv2_imshow(black_image)"
      ],
      "metadata": {
        "id": "Vs8Wu-qqmxst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using matplotlib to generate the histogram"
      ],
      "metadata": {
        "id": "iTc5jIXVAqHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(black_image.ravel(),256,[0,256])# syntax is .hist(image.ravel(), maximum number of bars in the graph, [range])\n",
        "                                         # The maximum number of bars in the graph for images should be 256 while the range should be [0, 255]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oe2ixx1KAzMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add more details into the image"
      ],
      "metadata": {
        "id": "4dzLDXolDnYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.rectangle(black_image, (0,100),(200,200),(255),-1)# -1 fills the rectange\n",
        "                                                      #syntax is:  rectangle(image, firstPoint, secondPoint, color, thickness)"
      ],
      "metadata": {
        "id": "YdEDskQjDmo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the histogram of the new image"
      ],
      "metadata": {
        "id": "m27vfoRuDnOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(black_image.ravel(),256,[0,256])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pF5M96kXDm2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding more pixels into the image"
      ],
      "metadata": {
        "id": "aIcPcLsjF8ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.rectangle(black_image, (0,50),(100,100),(127),-1)"
      ],
      "metadata": {
        "id": "CQXjZjrlF7_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing the new image's histogram again"
      ],
      "metadata": {
        "id": "b_9EdehzGNK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(black_image.ravel(),256,[0,256])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "88sMxL7tGPdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the histogram of an external image"
      ],
      "metadata": {
        "id": "VDhI4WxaGdHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extImage = cv2.imread(\"sheep.jpg\",0)# 0 is for grayscale\n",
        "cv2_imshow(extImage)\n",
        "\n",
        "\n",
        "plt.hist(extImage.ravel(),256,[0,256])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LTZGo9NEGdek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a histogram of an RGB image"
      ],
      "metadata": {
        "id": "k7LKnlmiHRfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extImageRGB = cv2.imread(\"sheep.jpg\")\n",
        "b, g ,r = cv2.split(extImageRGB)#Extracts the BGR values from an image\n",
        "\n",
        "cv2_imshow(extImageRGB)\n",
        "cv2_imshow(b)\n",
        "cv2_imshow(g)\n",
        "cv2_imshow(r)"
      ],
      "metadata": {
        "id": "FsxZHX6_HRVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating histograms of each RGB value"
      ],
      "metadata": {
        "id": "GowgA8FcHoRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(r.ravel(),256,[0,256], color=\"red\")\n",
        "plt.show()\n",
        "plt.hist(g.ravel(),256, [0,256], color=\"green\")\n",
        "plt.show()\n",
        "plt.hist(b.ravel(), 256, [0,256], color=\"blue\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(r.ravel(),256,[0,256], color=\"red\")\n",
        "plt.hist(g.ravel(),256, [0,256], color=\"green\")\n",
        "plt.hist(b.ravel(), 256, [0,256],color=\"blue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JcHTVWKaH0Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method in OpenCV that calculates the histogram of an image"
      ],
      "metadata": {
        "id": "Yt-X5_oiJCQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extImageRGB = cv2.imread(\"sheep.jpg\",0)\n",
        "\n",
        "hist = cv2.calcHist([extImageRGB], [0], None, [256], [0,256]) #Syntax .calcHist([image], [channels], Mask, [binCount], [Ramnge])\n",
        "\n",
        "plt.plot(hist)"
      ],
      "metadata": {
        "id": "F8HwgIirJGWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For RGB values each value needs to have its own histogram created for it."
      ],
      "metadata": {
        "id": "XtZIe5sHKArm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blurring"
      ],
      "metadata": {
        "id": "HYS6TII5YvTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blurring is used alongside smoothing to help remove noise from an image. To confirm how much noise a bluring technique has removed, it must be smoothen."
      ],
      "metadata": {
        "id": "Cnm0wDZoaAWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From video: https://www.youtube.com/watch?v=1oskz-0cH0c&ab_channel=PropagateKnowledge"
      ],
      "metadata": {
        "id": "1_FxD9xFYxOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Libraries"
      ],
      "metadata": {
        "id": "Oq3v_goTYzof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "9g4CosW9Y2HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Open Image"
      ],
      "metadata": {
        "id": "3Kmag277ZQ7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"cat.jpg\")\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "k7m3eFEvZQ0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Average Blurring"
      ],
      "metadata": {
        "id": "6MJgDkHTaFof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average blurring takes the average pixels under a certain area and replaces the central pixel with the average.\n",
        "\n",
        "Syntax: cv2.blur(image, (matrixWidth, matrixHeight))\n",
        "\n",
        "Usually blurs edges."
      ],
      "metadata": {
        "id": "0u3UShZzZwW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_blurred_image = cv2.blur(image, (50,50))\n",
        "cv2_imshow(average_blurred_image)"
      ],
      "metadata": {
        "id": "bv-USvFQZj-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Median Blur"
      ],
      "metadata": {
        "id": "PaMk_jyHal9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of taking the average, the median blur will replace the central pixel in the matrix with the median of the matrix.\n",
        "\n",
        "Syntax: cv2.medianBlur(image, matrixSize) where matrixSize must be an odd number and will be applied as the width and the height.\n",
        "\n",
        "It can preserve edges. (not blur them)"
      ],
      "metadata": {
        "id": "Az8DKw4TaqHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "median_blurred_image = cv2.medianBlur(image,13)\n",
        "cv2_imshow(median_blurred_image)"
      ],
      "metadata": {
        "id": "iW4uPcouamOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gaussian blur"
      ],
      "metadata": {
        "id": "qP6VIMp0bWF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gaussian blur takes the gaussian weights average of neighboring pixels around a pixel within a filter. The filter is a functional space alone, nearby pixels are considered while filtering, as in, it doesn't take into account that nearby pixels have the same or similar intensities. It doesn't care if the pixel is an edge or not an edge, therefore this blurring also blurs edges. Gaussian blur takes the gaussian weighted average in the coordinate space. It's not very useful.\n",
        "\n",
        ">Syntax: cv2.GaussianBlur(image, (matrixWidth, matrixHeight), deviation)\n",
        "\n",
        "deviation refers to the standard deviation of the space. The matrixWidth and matrixHeight must be odd numbers.\n",
        "\n",
        "Blurs edges"
      ],
      "metadata": {
        "id": "p9rZ3zEDbpYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gaussian_blurred_image = cv2.GaussianBlur(image,(51,51),0)\n",
        "cv2_imshow(gaussian_blurred_image)"
      ],
      "metadata": {
        "id": "R1VaaqAZbX7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilateral Blurring"
      ],
      "metadata": {
        "id": "CUJlfY95dG67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bilateral blurring takes into account the gaussian filter for space and another gaussian filter for the pixel difference. The gaussian filter for space uses the nearby pixel to calculate the weighted sum for blurring. The gaussian filter for the pixel difference uses pixel values whose intensity is similar to the central pixel. Bilateral blurring preserves edges because edges have a varying intensity. Whenever there is an edge, the intensity of the pixels on the edge varies (indicating the change of color). Usually produces better results than gaussian filter.\n",
        "\n",
        ">Syntax:  cv2.bilateralFilter(image,surroundingNumberOfPixels,deviationForColorSpace, deviationForCoordinateSpace)\n",
        "\n",
        "deviationForColorSpace should be between 5 and 150. deviationForColorSpace refers to the standard deviation of the color space.\n",
        "\n",
        "deviationForCoordinateSpace should be between 5 and 150. deviationForCoordinateSpace refers to the standard deviation of the color space.\n",
        "\n",
        "Doesn't blur edges."
      ],
      "metadata": {
        "id": "AjyF_27edXZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilateral_blurring_image = cv2.bilateralFilter(image,11,21,7)\n",
        "cv2_imshow(bilateral_blurring_image)"
      ],
      "metadata": {
        "id": "z7nBo_OfdHHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying the noise in the blurred and unblurred images"
      ],
      "metadata": {
        "id": "vBgQx-tufSox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise_original_image = cv2.Canny(image,2,15)\n",
        "cv2_imshow(noise_original_image)\n",
        "\n",
        "noise_average_image = cv2.Canny(average_blurred_image,2,15)\n",
        "cv2_imshow(noise_average_image)\n",
        "\n",
        "noise_median_image = cv2.Canny(median_blurred_image,2,15)\n",
        "cv2_imshow(noise_median_image)\n",
        "\n",
        "noise_guassian_image = cv2.Canny(gaussian_blurred_image,2,15)\n",
        "cv2_imshow(noise_guassian_image)\n",
        "\n",
        "noise_Bilatieral_image = cv2.Canny(bilateral_blurring_image,2,15)\n",
        "cv2_imshow(noise_Bilatieral_image)"
      ],
      "metadata": {
        "id": "-MVDCnGsfVcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binarization (Thresholding)"
      ],
      "metadata": {
        "id": "EVDIG_Pwfiyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea of thresholding comes from taking the histogram of the image and based on the the intensity values of the image, a certain line or \"threshold\" is placed where any intensities greater than the the threshold is set to the max value and everythign else is set to the minimum.\n",
        "\n",
        "There are a few binarization types:\n",
        "\n",
        ">Global Thresholding Techniques:\n",
        "\n",
        "* Normal Binary Thresholding: If the value of the pixel is greater than the threshold, set it to the maximum possible value. Otherwise set it to 0.\n",
        "\n",
        "* Inverse Binary Thresholding: If the value of the pixel is greater than the threshold, set it to 0. Otherwise set it to the maximum possible value.\n",
        "\n",
        "* Truncation Thresholding: If the value of the pixel is greater than the threshold, set it to the threshold hold, otherwise keep it as it is.\n",
        "\n",
        "* Thresholding to Zero: If the value of the pixel is greater than the threshold, leave it as it is. Otherwise set it to zero. (Like ReLU)\n",
        "\n",
        "* Inverse Thresholding to Zero: If the value of the pixel is greather than the threshold, it is set to zero. Otehrwise keep it as it is.\n",
        "\n",
        "* Otsu Thresholding: Is used to generate an optimal global threshold automatically.\n",
        "\n",
        "* Triange Thresholding: Is used to generate an optimal global threshold automatically. Works by creating a line between the highest value and the furthest non-zero frequency value (should be on the end of the longer tail). The intensity point (on the x-axis) that creates the highest distance between the line and the point becomes the threshold.\n",
        "\n",
        "\n",
        ">Adaptive Thresholding Techniques:\n",
        "\n",
        "* Mean Thresholding: The thrshold value is the mean of the area minus C. Takes into account the entire region equally.\n",
        "\n",
        "* Gaussian Thresholding: The threshold value is the weights sum of the neighboring area where the weight is the gaussian window minus C. Focuses on the pixels closest.\n",
        "\n",
        "\n",
        "\n",
        "For more details:\n",
        "\n",
        "https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa9e58d2860d4afa658ef70a9b1115576\n",
        "\n",
        "https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#threshold"
      ],
      "metadata": {
        "id": "juBK7EtXzcEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global Binarization"
      ],
      "metadata": {
        "id": "pZhIqSIjfwxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few types of global binarization:\n",
        "\n",
        "* Manual\n",
        "* Otsu\n",
        "* Triangle\n"
      ],
      "metadata": {
        "id": "Lz3Am0UU2d4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual Binarization (with manual grayscale)"
      ],
      "metadata": {
        "id": "oI70ZLz22qny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In manual binarization, the threshold is found manually."
      ],
      "metadata": {
        "id": "uganGlHt5BlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Import Libraries"
      ],
      "metadata": {
        "id": "rbvXziP72xQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM6bAvukvDT-"
      },
      "outputs": [],
      "source": [
        "from matplotlib.image import imread\n",
        "import matplotlib.pyplot as plt #Display images\n",
        "import numpy as np #Manipulate Arrays\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Read Image"
      ],
      "metadata": {
        "id": "vmcA5ecwgJcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = cv2.imread(\"sheep.jpg\") #get image\n"
      ],
      "metadata": {
        "id": "HD9lYDSCgMkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Get RGB Values From Image"
      ],
      "metadata": {
        "id": "2eIid7lsgNdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r,g,b = input_image[:,:,0],input_image[:,:,1],input_image[:,:,2]"
      ],
      "metadata": {
        "id": "1-UA2VLBgPfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Set Gamma"
      ],
      "metadata": {
        "id": "hm1Gu25mgSpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 1.04 #This is the gamma"
      ],
      "metadata": {
        "id": "KUMeaZrZgRhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Initialize constants for the rgb to grayscale formula"
      ],
      "metadata": {
        "id": "wnSgbW4agXlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_const,g_const,b_const = 0.216, 0.7152, 0.0722 #These are the constants from the rgb to greyscale formula\n"
      ],
      "metadata": {
        "id": "O2l85b--gb0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Order the RGB channels correctly\n",
        "\n",
        "Opencv reads in BGR i want it to be set back to RGB"
      ],
      "metadata": {
        "id": "2h62-gAFgdg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "l7THsyh2gdUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Apply RGB to Gray Scale Formula"
      ],
      "metadata": {
        "id": "PhXEgH4vgmi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grayscale_image = r_const*r**gamma + g_const*g**gamma + b_const*b**gamma"
      ],
      "metadata": {
        "id": "Y_L6_oGWgIaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Setting a global threshold to convert grayscale to binary"
      ],
      "metadata": {
        "id": "tKc5yi2lgwEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresh, binary_image = cv2.threshold(grayscale_image , 140, 255, cv2.THRESH_BINARY)"
      ],
      "metadata": {
        "id": "LUmDcHQqgvzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Viewing the binarized image"
      ],
      "metadata": {
        "id": "oG8iL_i_husV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(input_image)\n",
        "cv2_imshow(grayscale_image)\n",
        "cv2_imshow(binary_image)"
      ],
      "metadata": {
        "id": "kD18WZxYhwEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manual Binarization with Opencv gray scale shortcut"
      ],
      "metadata": {
        "id": "ES33qBKYiBn9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHa1X2lMj0VH"
      },
      "source": [
        "RGB constants and values as well as gamma are not needed when using cv2.cvtColor() function which automatically converts to gray scale or binary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Read Image"
      ],
      "metadata": {
        "id": "SFYQ1jEviIQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = cv2.imread(\"sheep.jpg\") #get image"
      ],
      "metadata": {
        "id": "oyTHGYcUiJcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Convert Image to grayscale"
      ],
      "metadata": {
        "id": "anqCycZ_iKLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xh764-B1yL36"
      },
      "outputs": [],
      "source": [
        "grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Setting a global threshold to convert grayscale to binary"
      ],
      "metadata": {
        "id": "StcwCyTMiab4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Biq8h3MzYOA"
      },
      "outputs": [],
      "source": [
        "thresh, binary_image = cv2.threshold(grayscale_image , 140, 255, cv2.THRESH_BINARY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QXAtUKpb19u_"
      },
      "outputs": [],
      "source": [
        "cv2_imshow(input_image)\n",
        "cv2_imshow(grayscale_image)\n",
        "cv2_imshow(binary_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adaptive Binarization"
      ],
      "metadata": {
        "id": "SMKEDLHqeR-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few types of adaptive thresholding techniques:\n",
        "\n",
        "* Mean\n",
        "* Gaussian\n",
        "* Sauvola\n",
        "* NiBlack"
      ],
      "metadata": {
        "id": "va4dL_oM3gqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A good note for adaptive binarization is:**\n",
        "\n",
        "The block size should be chosen such that a block always sees both foreground and background. If the block is too small, a block that is completely inside the foreground or background will not see the actual contrast in the region, it will only see the noise. Consequently, for that block, the thresholded result will not separate background and foreground, but noise within the single phase.\n",
        "\n",
        "The threshold value C can be zero if every block sees a good amount of both phases.\n",
        "\n",
        "If the block size cannot be chosen large enough, and some blocks see only background, then the C value can be set large enough for these blocks to result in only background. Two times the standard deviation of the noise in the background is a good start value.\n",
        "\n",
        "Likewise, if it is the foreground phase that is larger, set C to a negative value such that a block completely in the foreground results in only foreground.\n",
        "\n",
        "\n",
        "from: https://stackoverflow.com/a/61471278/17870878"
      ],
      "metadata": {
        "id": "aTLTTG3s57IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initial Testing"
      ],
      "metadata": {
        "id": "MYWaP_7ZmSgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input_image = imread(\"yo.jpg\")\n",
        "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert to grayscale\n",
        "grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "blurred_image = cv2.GaussianBlur(grayscale_image, (5,5), 0)\n",
        "#blurred_image = cv2.medianBlur(grayscale_image,1)\n",
        "# Adjust kernel size as needed\n",
        "print(type(blurred_image))\n",
        "# Apply adaptive thresholding\n",
        "binary_image = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 21, 7)\n",
        "# The number '11' defines block size and '2' is a constant subtracted from mean. Adjust these numbers as needed.\n",
        "\n",
        "plt.imshow(input_image)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(grayscale_image)\n",
        "plt.show()\n",
        "\n",
        "cv2_imshow(binary_image)\n",
        "plt.imshow(binary_image,cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TOyQP0pNq8AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "input_image = imread(\"yo3.jpg\")\n",
        "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Convert to grayscale\n",
        "grayscale_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\n",
        "# Adjust kernel size as needed\n",
        "print(type(blurred_image))\n",
        "# Apply adaptive thresholding\n",
        "binary_image = cv2.ximgproc.niBlackThreshold(grayscale_image, 255, cv2.THRESH_BINARY, 11, -0.2, binarizationMethod=cv2.ximgproc.BINARIZATION_NICK)\n",
        "\n",
        "# The number '11' defines block size and '2' is a constant subtracted from mean. Adjust these numbers as needed.\n",
        "\n",
        "plt.imshow(input_image)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(grayscale_image)\n",
        "plt.show()\n",
        "\n",
        "cv2_imshow(binary_image)\n",
        "plt.imshow(binary_image,cmap=plt.cm.binary)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5wzPm4YwCK-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### From Video: https://www.youtube.com/watch?v=Zf1F4cz8GHU&ab_channel=ProgrammingKnowledge"
      ],
      "metadata": {
        "id": "C9fxEHDxmWAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The threshold is calculated for a small region. There will be different threshold values for different regions.\n",
        "\n",
        "Simple thresholding is not the best for all conditions. Some images have different lighting in different regions where they vary from point to point and need a different threshold."
      ],
      "metadata": {
        "id": "snYdvnmEmd39"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Read Image"
      ],
      "metadata": {
        "id": "lFEecbmvm4MR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read Image as Gray scale\n",
        "image = cv2.imread(\"Lots Of Text.jpg\",cv2.IMREAD_GRAYSCALE)"
      ],
      "metadata": {
        "id": "VeQly0EOmY8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Applying basic global thresholding on the image"
      ],
      "metadata": {
        "id": "QHIHzb-CnBHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ , globalThreshold = cv2.threshold(image, 160,255, cv2.THRESH_BINARY)\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv2_imshow(globalThreshold) #Lots of black regions in the image"
      ],
      "metadata": {
        "id": "ME5_CY_mm9VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Applying adaptive thresholding"
      ],
      "metadata": {
        "id": "JV8t4vZotMQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax: cv2.adaptiveThrshold(image, maxValue, adaptiveMethod, thresholdType, blockSize, ValueOfC)\n",
        "\n",
        "\n",
        "There are two types of adaptive methods:\n",
        "\n",
        "* cv2.ADAPTIVE_THRESH_MEAN_C: The thrshold value is the mean of the area minus C. Takes into account the entire region equally.\n",
        "\n",
        "* cv2.ADAPTIVE_THRESH_GAUSSIAN_C: The threshold value is the weights sum of the neighboring area where the weight is the gaussian window minus C. Focuses on the pixels closest.\n",
        "\n",
        "\n",
        "Documentation: https://docs.opencv.org/4.x/d7/d1b/group__imgproc__misc.html#gaa42a3e6ef26247da787bf34030ed772c\n"
      ],
      "metadata": {
        "id": "BpNQ1APAsAo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adaptive_threshold_mean = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15,10)\n",
        "adaptive_thrshold_gaussian = cv2.adaptiveThreshold(image,255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15,10)"
      ],
      "metadata": {
        "id": "Sm3DZiK3qFWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### View the Adaptive Threshold Images"
      ],
      "metadata": {
        "id": "g19aVW28ttx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean:\")\n",
        "cv2_imshow(adaptive_threshold_mean)\n",
        "print(\"\\n\\nGaussian:\")\n",
        "cv2_imshow(adaptive_thrshold_gaussian)"
      ],
      "metadata": {
        "id": "AjDe8AtXtXtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Processing in OpenCV from Youtube"
      ],
      "metadata": {
        "id": "aIM5506eRbht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on video: https://www.youtube.com/watch?v=oXlwWbU8l2o&ab_channel=freeCodeCamp.org"
      ],
      "metadata": {
        "id": "eK0TACkWRezD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "JraFg3oXmPLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yJSTokncRjP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Images and Videos"
      ],
      "metadata": {
        "id": "IVUxl1W7f0Br"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading Images"
      ],
      "metadata": {
        "id": "HKpqof-3g0Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "images can be read in opencv by using imread(). It basically takes an image as input and returns it as an array of images."
      ],
      "metadata": {
        "id": "KHRnkSwogGAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('cat.jpg')"
      ],
      "metadata": {
        "id": "EdFYp4DSfVxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing the image"
      ],
      "metadata": {
        "id": "UwuFyWG1gY-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "4vP5NZX3gXFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading Videos"
      ],
      "metadata": {
        "id": "D3j-RcR2g1md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Commenting out the code here so i don't have trouble running all the cells at once*"
      ],
      "metadata": {
        "id": "p0PhPNY6uaLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Videos can be read using VideoCapture() in OpenCV. Usually, a path is given if the video to be read is stored on the device. But if a webcam is to be used then an integer argument is given like 0 or 1 etc. depending on which input device it should be using. In most cases it's going to be zero if there's only one web cam."
      ],
      "metadata": {
        "id": "kRJubMa7hAzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#capture = cv2.VideoCapture('Goku Super Saiyan.mp4')"
      ],
      "metadata": {
        "id": "1pmrwnBGgg-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to view a video, a loop must used to view it frame by frame. It can't be viewed as a video in colab but it works great in normal python. Each frame can be read as an array of pixels (like an image)."
      ],
      "metadata": {
        "id": "2EcUFLdMhgwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# frameNumber = 0\n",
        "\n",
        "# while frameNumber<5:\n",
        "#   isTrue, frame = capture.read() #returns the frame and whether or not the frame has been read correctly\n",
        "#   if not isTrue:\n",
        "#     print(\"Error reading a frame\")\n",
        "#     break\n",
        "\n",
        "#   cv2_imshow(frame)\n",
        "\n",
        "#   frameNumber+=1\n",
        "\n",
        "# #Releasing the capture pointer\n",
        "# capture.release()"
      ],
      "metadata": {
        "id": "kUvehOJyhxet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rescaling Images in OpenCV"
      ],
      "metadata": {
        "id": "L9ogxUxqjK4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rescaling and resizing is usually done to lower computer strain, so it doesn't have to store nor process all the information that is contained in the image. Rescaling refers to modifying the height and width of the image to a new height and width. Usually, it's better to downscale (lower the height and width)."
      ],
      "metadata": {
        "id": "S6dhXDf7kPbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('cat.jpg')\n",
        "\n",
        "scaleValue = 0.2\n",
        "\n",
        "width = int(image.shape[1]*scaleValue)\n",
        "height = int(image.shape[0]*scaleValue)\n",
        "\n",
        "dimensions = (width,height)\n",
        "\n",
        "resizedImage = cv2.resize(image, dimensions, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "cv2_imshow(resizedImage)"
      ],
      "metadata": {
        "id": "vqnFaBQMkOna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drawing shapes and wrting text in an image"
      ],
      "metadata": {
        "id": "5mt2IlfUlQxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two ways to do this:\n",
        "\n",
        "* Drawing on the original image\n",
        "* Drawing on a temporary image"
      ],
      "metadata": {
        "id": "FUzoSpmFpw_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('cat.jpg')\n",
        "\n",
        "blank = np.zeros((500,500,3), dtype='uint8')\n",
        "\n",
        "cv2_imshow(blank)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "FrvuUZVmpi4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Painting the image a certain color"
      ],
      "metadata": {
        "id": "XBaw3qm4qBJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Changes all colors to green\n",
        "\n",
        "blank [:] = 0,255,0 # [:] references all the pixels\n",
        "\n",
        "cv2_imshow(blank)\n",
        "\n",
        "\n",
        "#Change all colors to red\n",
        "\n",
        "blank[:] = 0,0,255\n",
        "\n",
        "cv2_imshow(blank)\n",
        "\n",
        "blank[:] = 0,0,0\n",
        "\n",
        "#Can paint certain pixelsa certain color\n",
        "\n",
        "blank[200:300, 300:400] = 255,0,0\n",
        "cv2_imshow(blank)\n",
        "\n",
        "blank[:] = 0,0,0"
      ],
      "metadata": {
        "id": "5p-XTNNop9X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drawing a rectangle"
      ],
      "metadata": {
        "id": "S90df2nhqX-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax of rectangle() is: rectangle(image, point1, point2, color, thickness, lineType)\n",
        "\n",
        "point1 and point2 refer to the top left and bottom right corners of the rectangle"
      ],
      "metadata": {
        "id": "qSMyPeMEqvC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.rectangle(blank, (0,0), (250,250), (0,255,0), thickness=2)#To fill the rectangle specify the thicnkess to cv2.FILLED or -1\n",
        "\n",
        "cv2_imshow(blank)\n",
        "\n",
        "blank[:] = 0,0,0"
      ],
      "metadata": {
        "id": "Z69fxyf5qrSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drawing a Circle"
      ],
      "metadata": {
        "id": "Zb5pcKfBrL7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The syntax of circle() is: circle(image, centerOfCircle, radius, color, thickness, lineType)\n",
        "\n",
        "\n",
        "centerOfCircle takes in a coordinate."
      ],
      "metadata": {
        "id": "vt34JMFGrvAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.circle(blank, (250,250), 40, (0,0,255), thickness=-1)\n",
        "\n",
        "cv2_imshow(blank)\n",
        "\n",
        "blank[:] = 0,0,0"
      ],
      "metadata": {
        "id": "r8-EQMHWrshA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drawing a line"
      ],
      "metadata": {
        "id": "3QflaGhFsCd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The syntax of line() is: line(image, point1, point2, color, thickness, lineType)\n",
        "\n",
        "point1 and point2 refer to the begining and the end of the line.\n",
        "\n",
        "Thickness = -1 doesn't work here."
      ],
      "metadata": {
        "id": "x14ncQmhsL31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.line(blank, (250,250), (0,0),(255,255,255), thickness=3)\n",
        "\n",
        "cv2_imshow(blank)\n",
        "\n",
        "blank[:] = 0,0,0"
      ],
      "metadata": {
        "id": "jWF3R9E7sJ54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing text on an image"
      ],
      "metadata": {
        "id": "IQ9FCeinD_Er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax for putText() is: putText(image, text, position , fontFace, fontSize, color, thickess, lineType)"
      ],
      "metadata": {
        "id": "TDqvxi3TFbTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.putText(blank, \"Hello World\",(150,200), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255),thickness=2)\n",
        "\n",
        "cv2_imshow(blank)"
      ],
      "metadata": {
        "id": "9bOMMLXkFaEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some basic essential functions"
      ],
      "metadata": {
        "id": "6t9w8CHRF3qx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Converting color code of an image\n",
        "2. Basic blurring of an image\n",
        "3. Edge cascading (Edge detection)\n",
        "4. Dilating images based on a structure\n",
        "5. Eroding miages based on a structure\n",
        "6. Resizing images\n",
        "7. Cropping images"
      ],
      "metadata": {
        "id": "LbEALZ3zGozX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting an image to grayscale"
      ],
      "metadata": {
        "id": "abLbxF5TGD10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, an image is read in BGR.\n",
        "\n",
        "The syntax for cvtColor() is: (image, colorCode)\n",
        "\n",
        "colorCode can refer to grayscale, RGB etc. *no block and white*"
      ],
      "metadata": {
        "id": "W90SqX-BGKqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('cat.jpg')\n",
        "\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Graysacale Image\")\n",
        "cv2_imshow(gray)"
      ],
      "metadata": {
        "id": "03PMJUyoGCkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Basic blurring of an image"
      ],
      "metadata": {
        "id": "R63QgGBuGnRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blurring an image is used for removing noise from an image. Noise could be due to bad brightness or a bad sensor etc. Applying a slight blur may be able to reduce the noise. There are a lot more techniques that will be seen later on.\n",
        "\n",
        "For now:\n",
        "\n",
        "The syntax of GaussianBlur() is: GaussianBlur(image, kernalSize, sigmaX)\n",
        "\n",
        "\n",
        "kernalSize is a tuple and it's value must be odd.\n",
        "\n",
        "sigmaX should be cv2.BORDER_DEFAULT"
      ],
      "metadata": {
        "id": "7rgR9BHZG3WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blurred = cv2.GaussianBlur(image, (3,3), cv2.BORDER_DEFAULT)\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Graysacale Image\")\n",
        "cv2_imshow(blurred)"
      ],
      "metadata": {
        "id": "YfqLu332G7d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edge Cascade"
      ],
      "metadata": {
        "id": "2iWj4e2MH6MH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edge cascading is basically trying to find edges present in the image. There are lots of types. But for now the one that is going be used is uncanny edge.\n",
        "\n",
        "Syntax for Canny() is: Canny(image, threshold1, threshold2)"
      ],
      "metadata": {
        "id": "Ai210F6cH-fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cany = cv2.Canny(image, 125,175)\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Cany Image\")\n",
        "cv2_imshow(cany)\n"
      ],
      "metadata": {
        "id": "QzrVbcUzILXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edges can be reduced by blurring the image:"
      ],
      "metadata": {
        "id": "qs6TkRJ4IZaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blurredCany = cv2.Canny(blurred,125,175)\n",
        "\n",
        "cv2_imshow(blurredCany)"
      ],
      "metadata": {
        "id": "q0WByMeDImAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dilating an image based on a structured element"
      ],
      "metadata": {
        "id": "Bleqy2XSIvcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case it will be based on the detected edges\n",
        "\n",
        "Syntax for dilate() is: dilate(image, kernalSize, iterations)"
      ],
      "metadata": {
        "id": "mMvEqpjPI_LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dilated = cv2.dilate(cany, (7,7),iterations=3)\n",
        "\n",
        "print(\"Cany Image\")\n",
        "cv2_imshow(cany)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Dialted Image\")\n",
        "cv2_imshow(dilated)"
      ],
      "metadata": {
        "id": "NAzQVv4AI-YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eroding Imges"
      ],
      "metadata": {
        "id": "64IS_BfAJQks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax for erode() is: erode(image, kernalSizem iterations)"
      ],
      "metadata": {
        "id": "b5fmwhDbJnZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eroded = cv2.erode(dilated,(7,7),iterations=3)\n",
        "\n",
        "print(\"Dilated Image\")\n",
        "cv2_imshow(dilated)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Eroded Image\")\n",
        "cv2_imshow(eroded)"
      ],
      "metadata": {
        "id": "JUHVtZ2DJjJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resizing and cropping images"
      ],
      "metadata": {
        "id": "7nHvUCLVJybl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax for resize() is: resize(image,sizem interpolation)\n",
        "\n",
        "size is a tuple\n",
        "\n",
        "It outputs an image that i gnores the aspect ratio\n",
        "\n",
        "\n",
        "If not specified, the interporlation is INTER_LINEAR.\n",
        "\n",
        "\n",
        "\n",
        "The different interpolation methods: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121\n",
        "\n",
        "\n",
        "Recommendations: https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d"
      ],
      "metadata": {
        "id": "h5Z4TyvIKQ1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized = cv2.resize(image,(500,500),interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Resized Image\")\n",
        "cv2_imshow(resized)"
      ],
      "metadata": {
        "id": "DQ_p8xmqKJfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cropping"
      ],
      "metadata": {
        "id": "lTjWLfhuKdVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cropped = image[50:200, 200:400]\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Cropped Image\")\n",
        "cv2_imshow(cropped)"
      ],
      "metadata": {
        "id": "mV_o3Y8jLq0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic image transformations"
      ],
      "metadata": {
        "id": "lwcatE4PL1eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Includes:\n",
        "\n",
        "1. Translation\n",
        "2. Rotation\n",
        "3. Resizing\n",
        "4. Flipping\n",
        "5. Cropping"
      ],
      "metadata": {
        "id": "bZJhV5TTof8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translation"
      ],
      "metadata": {
        "id": "GyrRcDETL6_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translation refers to shifting an image in any direction (up, left, downm right\n",
        " or any combination)."
      ],
      "metadata": {
        "id": "J-qw0H2wphOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('cat.jpg')\n",
        "\n",
        "movePixelsOnX = 100 #To go left specify a negative number\n",
        "movePixelsOnY = 100 #To go down specify a negative number\n",
        "\n",
        "transformationMatrix = np.float32([[1,0,movePixelsOnX],[0,1,movePixelsOnY]])\n",
        "dimensions = (image.shape[1],image.shape[0])\n",
        "\n",
        "translatedImage = cv2.warpAffine(image,transformationMatrix,dimensions)\n",
        "\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Translated Image Image\")\n",
        "cv2_imshow(translatedImage)"
      ],
      "metadata": {
        "id": "l1Al3injocgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotation"
      ],
      "metadata": {
        "id": "U03TmyBvqw-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any point in the image can be specified to be rotated (Usually it's the center)."
      ],
      "metadata": {
        "id": "K9h4qs9Gq0M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "angle = 20 # To rotate clockwise specify a negative number\n",
        "\n",
        "(height,width) = image.shape[:2]\n",
        "\n",
        "centerRotationPoint = (width//2,height//2)\n",
        "\n",
        "rotationMatrix = cv2.getRotationMatrix2D(centerRotationPoint, angle,1.0) # The 1.0 is the scale. 1.0 means to keep the scale as it is\n",
        "\n",
        "dimensions = (width,height)\n",
        "\n",
        "rotatedImage = cv2.warpAffine(image, rotationMatrix,dimensions)\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Rotated Image Image\")\n",
        "cv2_imshow(rotatedImage)"
      ],
      "metadata": {
        "id": "WPc40vInqzM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resizing an image"
      ],
      "metadata": {
        "id": "2NJ7MbhGsGFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resized = cv2.resize(image, (500,500),interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Resized Image\")\n",
        "cv2_imshow(resized)"
      ],
      "metadata": {
        "id": "QQfPdQI5sHa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flipping an Image"
      ],
      "metadata": {
        "id": "jA7ecYgjsd2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax for flip() is: flip(image, flipCode)\n",
        "\n",
        "flipCode can be 0,1 or -1, where:\n",
        "\n",
        "* 0 flips the image vertically over the x-axis\n",
        "* 1 flips the image horizontally over they y-axis\n",
        "* -1 flips hte image vertically and horizontally"
      ],
      "metadata": {
        "id": "Z3ibr83Is3EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flippedImageVertically = cv2.flip(image,0)\n",
        "flippedImageHorizontally = cv2.flip(image,1)\n",
        "flippedImageBoth= cv2.flip(image,-1)\n",
        "\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Vertically Flipped Image\")\n",
        "cv2_imshow(flippedImageVertically)\n",
        "\n",
        "print()\n",
        "\n",
        "\n",
        "print(\"Horizontally Flipped Image\")\n",
        "cv2_imshow(flippedImageHorizontally)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Vertically and Horizontally Flipped Image\")\n",
        "cv2_imshow(flippedImageBoth)"
      ],
      "metadata": {
        "id": "3g1Fpw3PsxIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cropping"
      ],
      "metadata": {
        "id": "_-wo9lMHtwPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cropped = image[100:400, 500:800]\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Cropped Image\")\n",
        "cv2_imshow(cropped)"
      ],
      "metadata": {
        "id": "tKmopphQtw4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contour Detection"
      ],
      "metadata": {
        "id": "oYpvbCVWuMUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contours are basically the boundaries of object, in other words the line or curve that joins the continous points along the boundary of an object. They're similar to edges but mathmatically are different. Contours are useful for shape analysi and object detection and recognition.\n",
        "\n",
        "Some techniques the get the Cannny Edges thresholds automatically [here](https://stackoverflow.com/questions/4292249/automatic-calculation-of-low-and-high-thresholds-for-the-canny-operation-in-open)"
      ],
      "metadata": {
        "id": "iY3tpYFZuQ3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Canny Edges of an image"
      ],
      "metadata": {
        "id": "2Kh6xXJhwjvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"cat.jpg\")\n",
        "\n",
        "grayImage = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "canny = cv2.Canny(image,100,150)\n",
        "\n",
        "\n",
        "print(\"Original Image\")\n",
        "cv2_imshow(image)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Canny Image\")\n",
        "cv2_imshow(canny)"
      ],
      "metadata": {
        "id": "ovcenH3MuNOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find the contours"
      ],
      "metadata": {
        "id": "Bys2ELLAwe_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntax for findContours() is: findCountours(edges, mode, contourApprxMethod)\n",
        "\n",
        "\n",
        "mode can be:\n",
        "\n",
        "* cv2.RETR_TREE to get all the heirarchal contours\n",
        "* cv2.RETR_EXTERNAL to get only the external contours\n",
        "* cv2.RETR_LIST get all the contours in the image\n",
        "\n",
        "\n",
        "Countours returns all"
      ],
      "metadata": {
        "id": "tSgcitZFxWTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countours, hierarchies = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)"
      ],
      "metadata": {
        "id": "riEFB-1-xPCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JtHQUQW4zLCf",
        "8CNHQg3NePrA",
        "HYS6TII5YvTX",
        "MYWaP_7ZmSgd",
        "JraFg3oXmPLo",
        "IVUxl1W7f0Br",
        "5mt2IlfUlQxk",
        "6t9w8CHRF3qx"
      ],
      "authorship_tag": "ABX9TyM1PGO6nTjNV28gRvB6BbgL"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}